% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/rs_append_table.R
\name{rs_append_table}
\alias{rs_append_table}
\title{Append to redshift table}
\usage{
rs_append_table(df, server_name, table_name, keys, split_files,
  bucket = "tmp-metricarts", region = "us-east-1", iam_role_arn = "",
  wlm_slots = 1, threads = 0)
}
\arguments{
\item{df}{a data frame}

\item{server_name}{an RPostgres connection to the redshift server}

\item{table_name}{the name of the table to replace}

\item{keys}{athis optional vector contains the variables by which to upsert. If not defined, the upsert becomes an append.}

\item{split_files}{optional parameter to specify amount of files to split into. If not specified will look at amount of slices in Redshift to determine an optimal amount.}

\item{bucket}{the name of the temporary bucket to load the data. Will look for AWS_BUCKET_NAME on environment if not specified.}

\item{region}{the region of the bucket. Will look for AWS_DEFAULT_REGION on environment if not specified.}

\item{iam_role_arn}{an iam role arn with permissions fot the bucket. Will look for AWS_IAM_ROLE_ARN on environment if not specified. This is ignoring access_key and secret_key if set.}

\item{wlm_slots}{amount of WLM slots to use for this bulk load http://docs.aws.amazon.com/redshift/latest/dg/tutorial-configuring-workload-management.html}

\item{treads}{number of threads used to compress the csv files}
}
\description{
Upload a table to S3 and then load it with redshift appending data to the existing table
The table on redshift has to have the same structure and column ordering to work correctly.
}
\examples{
library(DBI)

a=data.frame(a=seq(1,10000), b=seq(10000,1))
n=head(a,n=5000)
n$b=n$a
nx=rbind(n, data.frame(a=seq(99999:104000), b=seq(104000:99999)))

\dontrun{
con <- dbConnect(RPostgres::Postgres(), dbname="dbname",
host='my-redshift-url.amazon.com', port='5439',
user='myuser', password='mypassword',sslmode='require')

rs_append_table(df=nx, dbcon=con, table_name='testTable',
bucket="my-bucket", split_files=4, keys=c('a'))

}
}
